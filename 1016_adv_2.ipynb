{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\tonyyyyy/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import foolbox as fb\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.eval()\n",
    "with open(\"imagenet_labels.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "292\n",
      "331\n",
      "340\n",
      "366\n",
      "388\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# read in the image files from different folders and each folder corresponds to a label\n",
    "top = \"adv/\"\n",
    "index = 0\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "for root, dirs, files in os.walk(top, topdown=False):\n",
    "    for name in dirs:\n",
    "        temp = os.path.join(root, name)\n",
    "        for root1, dirs1, files1 in os.walk(temp, topdown=False):\n",
    "            for j in files1:\n",
    "                img_name = os.path.join(root1, j)\n",
    "                img = image.load_img(img_name)\n",
    "                data.append(img)\n",
    "                label.append(int(name))\n",
    "        print(name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "pred= []\n",
    "for i in data:\n",
    "  input_tensor = preprocess(i)\n",
    "  input_batch = input_tensor.unsqueeze(0)\n",
    "  input_batch = input_batch*2\n",
    "  input_batch = torch.round(input_batch)\n",
    "  input_batch = input_batch/2\n",
    "  feature = model(input_batch)\n",
    "\n",
    "  probabilities = torch.nn.functional.softmax(feature[0], dim=0)\n",
    "  top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "  pred.append(top5_catid[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "    if (label[i] == pred[i].int()):\n",
    "        count+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "152"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "154"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyyyyy\\AppData\\Local\\Temp/ipykernel_11080/3072561362.py:1: FutureWarning: The input object of type 'JpegImageFile' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'JpegImageFile', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data = np.array(data)\n",
      "C:\\Users\\tonyyyyy\\AppData\\Local\\Temp/ipykernel_11080/3072561362.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "label = np.array(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import eagerpy as ep\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD\n",
    "\n",
    "label = torch.tensor(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "pre = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "outputs = []\n",
    "\n",
    "for i in data:\n",
    "    tensor = pre(i)  #transform from (64, 1, 224, 224) to (64, 32, 224, 224)\n",
    "    outputs.append(tensor[None, :])\n",
    "\n",
    "result = torch.cat(outputs, dim=0)  #shape (64, 32*in_channels, 224, 224)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean accuracy:  98.1 %\n"
     ]
    }
   ],
   "source": [
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "clean_acc = accuracy(fmodel, result, label)\n",
    "print(f\"clean accuracy:  {clean_acc * 100:.1f} %\")\n",
    "attack = LinfPGD()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.1137, 0.1216, 0.1216,  ..., 0.4980, 0.4863, 0.4824],\n          [0.1098, 0.0980, 0.1020,  ..., 0.5059, 0.4941, 0.4824],\n          [0.1569, 0.1059, 0.0863,  ..., 0.5098, 0.4941, 0.4824],\n          ...,\n          [0.4392, 0.4078, 0.4039,  ..., 0.3882, 0.5137, 0.6078],\n          [0.4627, 0.4980, 0.4824,  ..., 0.5098, 0.6353, 0.4902],\n          [0.4863, 0.4941, 0.5255,  ..., 0.6549, 0.6118, 0.5255]],\n\n         [[0.1373, 0.1333, 0.1255,  ..., 0.5922, 0.5961, 0.5922],\n          [0.1333, 0.1059, 0.1059,  ..., 0.6000, 0.6000, 0.5922],\n          [0.1725, 0.1137, 0.0863,  ..., 0.6039, 0.6000, 0.5922],\n          ...,\n          [0.3608, 0.3294, 0.3255,  ..., 0.2941, 0.4196, 0.5137],\n          [0.3804, 0.4157, 0.4039,  ..., 0.4157, 0.5412, 0.4000],\n          [0.4000, 0.4078, 0.4392,  ..., 0.5647, 0.5176, 0.4353]],\n\n         [[0.0980, 0.1020, 0.0941,  ..., 0.7686, 0.7804, 0.7804],\n          [0.1020, 0.0824, 0.0824,  ..., 0.7765, 0.7882, 0.7804],\n          [0.1608, 0.1059, 0.0784,  ..., 0.7765, 0.7882, 0.7804],\n          ...,\n          [0.2824, 0.2431, 0.2431,  ..., 0.1961, 0.3137, 0.4039],\n          [0.3059, 0.3333, 0.3137,  ..., 0.3020, 0.4275, 0.2824],\n          [0.3333, 0.3294, 0.3490,  ..., 0.4314, 0.3922, 0.3098]]],\n\n\n        [[[0.7137, 0.7137, 0.7137,  ..., 0.4431, 0.4863, 0.4980],\n          [0.7137, 0.7137, 0.7176,  ..., 0.4510, 0.4941, 0.4980],\n          [0.7137, 0.7137, 0.7176,  ..., 0.4588, 0.4941, 0.4980],\n          ...,\n          [0.4235, 0.4431, 0.4510,  ..., 0.1373, 0.1490, 0.1412],\n          [0.4196, 0.4431, 0.4588,  ..., 0.1412, 0.1686, 0.1412],\n          [0.4118, 0.4314, 0.4667,  ..., 0.1412, 0.1608, 0.1451]],\n\n         [[0.8000, 0.8000, 0.8000,  ..., 0.4353, 0.4784, 0.4902],\n          [0.8000, 0.8000, 0.8039,  ..., 0.4431, 0.4863, 0.4902],\n          [0.8000, 0.8000, 0.8039,  ..., 0.4471, 0.4824, 0.4902],\n          ...,\n          [0.4431, 0.4627, 0.4667,  ..., 0.1020, 0.1098, 0.1020],\n          [0.4431, 0.4627, 0.4706,  ..., 0.1098, 0.1333, 0.0980],\n          [0.4392, 0.4549, 0.4745,  ..., 0.1059, 0.1216, 0.1059]],\n\n         [[0.8510, 0.8510, 0.8510,  ..., 0.3294, 0.3843, 0.3961],\n          [0.8510, 0.8510, 0.8549,  ..., 0.3412, 0.3961, 0.4039],\n          [0.8549, 0.8549, 0.8588,  ..., 0.3490, 0.3961, 0.4078],\n          ...,\n          [0.2824, 0.3059, 0.3176,  ..., 0.0980, 0.1059, 0.0980],\n          [0.2784, 0.3020, 0.3176,  ..., 0.1098, 0.1255, 0.0941],\n          [0.2706, 0.2941, 0.3216,  ..., 0.1059, 0.1176, 0.0941]]],\n\n\n        [[[0.7255, 0.7216, 0.7137,  ..., 0.6588, 0.6549, 0.6549],\n          [0.7294, 0.7255, 0.7176,  ..., 0.6510, 0.6510, 0.6549],\n          [0.7294, 0.7255, 0.7176,  ..., 0.6392, 0.6471, 0.6510],\n          ...,\n          [0.7882, 0.7843, 0.7843,  ..., 0.7059, 0.7059, 0.7059],\n          [0.7922, 0.7843, 0.7843,  ..., 0.7059, 0.7059, 0.7059],\n          [0.7843, 0.7765, 0.7686,  ..., 0.7020, 0.7020, 0.7020]],\n\n         [[0.6000, 0.5961, 0.5882,  ..., 0.5373, 0.5333, 0.5333],\n          [0.6039, 0.6000, 0.5922,  ..., 0.5294, 0.5294, 0.5333],\n          [0.6039, 0.6000, 0.5922,  ..., 0.5176, 0.5255, 0.5294],\n          ...,\n          [0.6392, 0.6392, 0.6392,  ..., 0.3765, 0.3765, 0.3765],\n          [0.6471, 0.6392, 0.6392,  ..., 0.3765, 0.3765, 0.3765],\n          [0.6392, 0.6314, 0.6235,  ..., 0.3725, 0.3725, 0.3725]],\n\n         [[0.4471, 0.4431, 0.4353,  ..., 0.4157, 0.4118, 0.4118],\n          [0.4510, 0.4471, 0.4392,  ..., 0.4078, 0.4078, 0.4118],\n          [0.4510, 0.4471, 0.4392,  ..., 0.3961, 0.4039, 0.4078],\n          ...,\n          [0.4431, 0.4353, 0.4314,  ..., 0.2745, 0.2745, 0.2745],\n          [0.4392, 0.4353, 0.4314,  ..., 0.2745, 0.2745, 0.2745],\n          [0.4314, 0.4235, 0.4157,  ..., 0.2706, 0.2706, 0.2706]]],\n\n\n        ...,\n\n\n        [[[0.4706, 0.4706, 0.4745,  ..., 0.9804, 0.9804, 0.9804],\n          [0.4706, 0.4706, 0.4745,  ..., 0.9804, 0.9804, 0.9804],\n          [0.4745, 0.4745, 0.4784,  ..., 0.9804, 0.9804, 0.9804],\n          ...,\n          [0.5843, 0.5804, 0.5725,  ..., 0.2824, 0.2863, 0.2824],\n          [0.5882, 0.5843, 0.5804,  ..., 0.2863, 0.2863, 0.2902],\n          [0.5961, 0.5961, 0.5922,  ..., 0.2941, 0.2902, 0.2902]],\n\n         [[0.4431, 0.4431, 0.4471,  ..., 0.9804, 0.9804, 0.9804],\n          [0.4431, 0.4431, 0.4471,  ..., 0.9804, 0.9804, 0.9804],\n          [0.4471, 0.4471, 0.4510,  ..., 0.9804, 0.9804, 0.9804],\n          ...,\n          [0.5451, 0.5412, 0.5373,  ..., 0.2941, 0.2980, 0.2980],\n          [0.5490, 0.5451, 0.5412,  ..., 0.2980, 0.2980, 0.3020],\n          [0.5490, 0.5490, 0.5451,  ..., 0.3020, 0.3020, 0.3020]],\n\n         [[0.3843, 0.3843, 0.3882,  ..., 0.9804, 0.9804, 0.9804],\n          [0.3804, 0.3804, 0.3843,  ..., 0.9804, 0.9804, 0.9804],\n          [0.3843, 0.3843, 0.3882,  ..., 0.9804, 0.9804, 0.9804],\n          ...,\n          [0.4314, 0.4275, 0.4235,  ..., 0.2471, 0.2510, 0.2510],\n          [0.4353, 0.4314, 0.4275,  ..., 0.2549, 0.2549, 0.2588],\n          [0.4431, 0.4392, 0.4353,  ..., 0.2588, 0.2588, 0.2588]]],\n\n\n        [[[0.2549, 0.2784, 0.3137,  ..., 0.2157, 0.2196, 0.2392],\n          [0.2588, 0.2824, 0.3137,  ..., 0.2157, 0.2196, 0.2510],\n          [0.2549, 0.2902, 0.3176,  ..., 0.2157, 0.2392, 0.2667],\n          ...,\n          [0.2235, 0.1843, 0.1765,  ..., 0.8980, 0.8824, 0.8745],\n          [0.2471, 0.2000, 0.2078,  ..., 0.9059, 0.8980, 0.8902],\n          [0.2941, 0.2353, 0.2627,  ..., 0.9020, 0.8980, 0.8902]],\n\n         [[0.2235, 0.2510, 0.2863,  ..., 0.2118, 0.2118, 0.2235],\n          [0.2235, 0.2510, 0.2863,  ..., 0.2078, 0.2078, 0.2353],\n          [0.2196, 0.2549, 0.2863,  ..., 0.2118, 0.2275, 0.2510],\n          ...,\n          [0.1882, 0.1569, 0.1451,  ..., 0.8980, 0.8863, 0.8784],\n          [0.2078, 0.1725, 0.1843,  ..., 0.9020, 0.8941, 0.8863],\n          [0.2431, 0.2000, 0.2353,  ..., 0.8980, 0.8941, 0.8863]],\n\n         [[0.1961, 0.2196, 0.2510,  ..., 0.2000, 0.2000, 0.2157],\n          [0.1961, 0.2235, 0.2510,  ..., 0.2118, 0.2118, 0.2392],\n          [0.1922, 0.2275, 0.2510,  ..., 0.2039, 0.2235, 0.2510],\n          ...,\n          [0.1451, 0.1059, 0.0902,  ..., 0.8784, 0.8667, 0.8627],\n          [0.1490, 0.1137, 0.1294,  ..., 0.8824, 0.8745, 0.8667],\n          [0.2000, 0.1569, 0.1922,  ..., 0.8784, 0.8745, 0.8667]]],\n\n\n        [[[0.0980, 0.0980, 0.0980,  ..., 0.1922, 0.1961, 0.2000],\n          [0.0980, 0.1020, 0.1020,  ..., 0.2000, 0.2078, 0.2078],\n          [0.1059, 0.1098, 0.1059,  ..., 0.2157, 0.2157, 0.2118],\n          ...,\n          [0.4000, 0.3922, 0.4235,  ..., 0.7176, 0.7176, 0.7255],\n          [0.3882, 0.4039, 0.4510,  ..., 0.7412, 0.7412, 0.7373],\n          [0.3255, 0.3647, 0.4275,  ..., 0.7569, 0.7608, 0.7529]],\n\n         [[0.2941, 0.2941, 0.2980,  ..., 0.3843, 0.3843, 0.3843],\n          [0.2902, 0.2941, 0.3020,  ..., 0.3922, 0.3882, 0.3882],\n          [0.3020, 0.3020, 0.3059,  ..., 0.3961, 0.4000, 0.3961],\n          ...,\n          [0.3490, 0.3333, 0.3608,  ..., 0.6431, 0.6314, 0.6314],\n          [0.3451, 0.3529, 0.3922,  ..., 0.6627, 0.6510, 0.6392],\n          [0.2902, 0.3294, 0.3686,  ..., 0.6667, 0.6627, 0.6510]],\n\n         [[0.4431, 0.4431, 0.4353,  ..., 0.5098, 0.5098, 0.5059],\n          [0.4471, 0.4471, 0.4392,  ..., 0.5176, 0.5176, 0.5137],\n          [0.4471, 0.4471, 0.4392,  ..., 0.5255, 0.5176, 0.5137],\n          ...,\n          [0.2588, 0.2510, 0.2784,  ..., 0.5529, 0.5373, 0.5255],\n          [0.2627, 0.2745, 0.3098,  ..., 0.5843, 0.5608, 0.5412],\n          [0.2196, 0.2510, 0.2941,  ..., 0.6000, 0.5804, 0.5569]]]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "fmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "raw_advs, clipped_advs, success = attack(fmodel, result, label.long(), epsilons=0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction correctly labeled image is: \n",
      "0.8441558441558441\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(clipped_advs)):\n",
    "    input_tensor = clipped_advs[i]\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    input_batch = input_batch*2\n",
    "    input_batch = torch.round(input_batch)\n",
    "    input_batch = input_batch/2\n",
    "    feature = model(input_batch)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(feature[0], dim=0)\n",
    "    top_prob, top_catid = torch.topk(probabilities, 1)\n",
    "    id = label[i]\n",
    "    if (id == top_catid):\n",
    "        count = count + 1\n",
    "print(\"The fraction correctly labeled image is: \")\n",
    "print(count/len(label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "iter = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(result)):\n",
    "\n",
    "    input_tensor = outputs[i]\n",
    "    input_batch = input_tensor*2\n",
    "    input_batch = torch.round(input_batch)\n",
    "    input_batch = input_batch/2\n",
    "    iter.append(input_batch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "iter = torch.cat(iter, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08323557674884796\n",
      "0.07452831417322159\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.1)\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(iter)\n",
    "    loss = criterion(outputs, label.long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}